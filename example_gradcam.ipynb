{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM | Ramprasaath R. Selvaraju\n",
    "Paper: <https://arxiv.org/abs/1610.02391> Github: <https://github.com/ramprs/grad-cam/tree/master>\\\n",
    "Example code and gradcam module revised from Deepsurv: <https://github.com/deepsurv-cnn/main/blob/main/visualization/gradcam>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shutil\n",
    "from importlib import reload\n",
    "\n",
    "from utils import *\n",
    "\n",
    "sys.path.append('./gradcam_module')\n",
    "import gradcam\n",
    "import utils_gradcam\n",
    "reload(gradcam)\n",
    "reload(utils_gradcam)\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from utils_gradcam import visualize_cam, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_numpy(tensor):\n",
    "    \"\"\"Converts a PyTorch tensor to a NumPy array.\"\"\"\n",
    "    if tensor.dim() == 4:  # For tensors with shape [1, 1, H, W] or [1, 3, H, W]\n",
    "        return tensor.squeeze().cpu().numpy()  # Remove the 1-dimensions and convert\n",
    "    elif tensor.dim() == 3:  # For tensors with shape [3, H, W]\n",
    "        return tensor.transpose(0, 2).transpose(0, 1).cpu().numpy()  # Reorder dimensions to [H, W, 3] and convert\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported tensor shape: {}\".format(tensor.shape))\n",
    "\n",
    "def de_min_max_scaling(img_np, pretrained):\n",
    "    if pretrained == 'TorchX':\n",
    "        img_np = (img_np / 1024 + 1 ) / 2 * 0.5\n",
    "        img_denormed = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "    elif pretrained == 'ImageN': \n",
    "        img_denormed = img_np + 0.5\n",
    "\n",
    "    return img_denormed\n",
    "\n",
    "def clahe(X_bbox, cl, gs):\n",
    "    clahe = cv2.createCLAHE(clipLimit=cl*gs*gs, tileGridSize=(gs, gs))\n",
    "    X_histeq = []\n",
    "    for i in range(len(X_bbox)):\n",
    "        # img = X_bbox[i] + 0.5\n",
    "        img = X_bbox[i,0,:,:] \n",
    "        img *= (255.0 / img.max())\n",
    "        img = img.astype('uint8')\n",
    "        img = clahe.apply(img)\n",
    "        X_histeq.append(img)\n",
    "\n",
    "    return X_histeq\n",
    "\n",
    "def preprocess_seg_id(X, y, y_id, sharpen, histeq, cl, gs, pretrained):\n",
    "    \n",
    "    X_bbox = []\n",
    "    img_size = 512\n",
    "    for i in range(len(X)):\n",
    "        ymin, ymax, xmin, xmax = bbox2_square(X[i,:,:,1])\n",
    "        img = X[i,:,:,0].astype(np.float32)\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        bbox = img[ymin:ymax+1, xmin:xmax+1]\n",
    "        bbox = cv2.resize(bbox, dsize=(img_size, img_size), interpolation=cv2.INTER_LINEAR)\n",
    "        X_bbox.append(bbox)\n",
    "    \n",
    "    X_bbox, y, y_id = shuffle(X_bbox, y, y_id)\n",
    "    X_bbox = np.array(X_bbox)\n",
    "    \n",
    "    if histeq == 'True':\n",
    "        X_histeq = clahe(X_bbox, cl, gs)\n",
    "        X_bbox = np.array(X_histeq)\n",
    "    else: \n",
    "        X_bbox = np.array(X_bbox)   \n",
    "\n",
    "    if sharpen == 'True':\n",
    "        X_sharp = sharpening(X_bbox)\n",
    "        X_bbox = np.array(X_sharp)\n",
    "    else:\n",
    "        X_bbox = np.array(X_bbox)\n",
    "    \n",
    "    X_processed = []\n",
    "    for i in range(len(X_bbox)):\n",
    "        bbox = min_max_scaling(X_bbox[i], pretrained)\n",
    "        X_processed.append(bbox)\n",
    "\n",
    "    print('after processing',np.min(X_processed),np.max(X_processed))\n",
    "\n",
    "    X_processed = np.expand_dims(X_processed, axis=-1)\n",
    "    \n",
    "    return X_processed, y, y_id\n",
    "\n",
    "def display_heatmap_on_image(img, heatmap, idx, id_test, y_test, preds, histpath, pretrained):\n",
    "    \"\"\"Displays a grayscale image and the same image with a heatmap overlay.\"\"\"\n",
    "\n",
    "    gradcamDir = os.path.join(histpath, 'gradcam-test')\n",
    "    if not os.path.exists(gradcamDir):\n",
    "        os.makedirs(gradcamDir)\n",
    "\n",
    "    img_np = tensor_to_numpy(img)  \n",
    "    img_np =  de_min_max_scaling(img_np, pretrained)\n",
    "    heatmap_np = tensor_to_numpy(heatmap)  \n",
    "\n",
    "    # Convert grayscale image to RGB format for display\n",
    "    img_rgb = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Overlay the heatmap on the image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_rgb, cmap='gray')\n",
    "    plt.title(id_test[idx]+\" actual: %s predicted: %s\" % (y_test[idx], preds), fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_rgb, cmap='gray')\n",
    "    plt.imshow(heatmap_np, alpha=0.5, cmap='jet')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(gradcamDir+'/{}.png'.format(id_test[idx]), format=\"PNG\")\n",
    "    plt.show()\n",
    "    # plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'TorchX-SBU-RSNA'\n",
    "pretrained = modelName.split('-')[0]\n",
    "\n",
    "histf = './history/'\n",
    "histpath = os.path.join(histf, modelName)\n",
    "\n",
    "gradcamDir = os.path.join(histpath, 'gradcam-test')\n",
    "if os.path.exists(gradcamDir):\n",
    "    shutil.rmtree(gradcamDir)\n",
    "\n",
    "# load testing data\n",
    "test_data = np.load('/path/to/test_data.npy')\n",
    "test_label = pd.read_csv('/path/to/test_label.csv')\n",
    "x_test = np.array(test_data)\n",
    "y_test = np.array(test_label['Label'].astype(int))\n",
    "id_test = np.array(test_label['ID'])\n",
    "# preprocessing according to pretrained model\n",
    "x_test, y_test, id_test = preprocess_seg_id(x_test, y_test, id_test, 'False', 'False', 0, 0, pretrained)\n",
    "x_test = np.transpose(x_test, (0, 3, 1, 2))\n",
    "x_test = torch.from_numpy(x_test)\n",
    "print('Testing data distribution')\n",
    "print('x_test', x_test.shape)\n",
    "print(\"True: \", y_test.sum())\n",
    "print(\"False: \",len(y_test) - y_test.sum())\n",
    "\n",
    "# load model\n",
    "weightPath  =  histpath + '/ckpt/model_fold_1_best.pt'\n",
    "model = load_model(pretrained)\n",
    "state_dict = torch.load(weightPath, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# generate gradcam\n",
    "target_layer = model.base_model.features.denseblock4.denselayer16\n",
    "gradcam = GradCAM(model.base_model, target_layer)\n",
    "num_images = 5\n",
    "for i in range(num_images):\n",
    "    idx = random.randint(0, len(y_test) - 1)\n",
    "    img = x_test[idx]\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.float()  \n",
    "\n",
    "    # get a GradCAM saliency map on the class index 10.\n",
    "    mask, _ = gradcam(img, class_idx=0)\n",
    "    # make heatmap from mask and synthesize saliency map using heatmap and img\n",
    "    heatmap, cam_result = visualize_cam(mask, img)\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients for inference\n",
    "        pred = model(img)\n",
    "    pred = torch.sigmoid(pred)\n",
    "    preds = int(pred >= 0.5)\n",
    "\n",
    "    display_heatmap_on_image(img, heatmap, idx, id_test, y_test, preds, histpath, pretrained)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
